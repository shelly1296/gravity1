{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.1 |Anaconda custom (64-bit)| (default, May 11 2017, 13:25:24) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 0.19.1\nnumpy: 1.12.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 2.0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 0.20.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 0.18.1\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "\n",
    "# In addition to the online example, these packages below help dealinf with the file system\n",
    "import glob\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory to parse, and the column names\n",
    "dir = \"C:/Users/Adam Shelboourne/Uni/Physics/Astr310/Python/mu/daily/\"\n",
    "#dir = \"/Users/AdamShelbourne/Uni/Physics/Astr310/Python/sso/daily\"\n",
    "\n",
    "# Set the column names for the data\n",
    "names = ['UTCDateTime', 'LocalDateTime', 'Temperature', 'Counts', 'Frequency', 'MSAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Adam Shelboourne/Uni/Physics/Astr310/Python/mu/daily/all_data.dat'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0b3402533a1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# storing the data of each night. These are merged later, but couldn't easily see how to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# do this directly in one file, due to mixed data types.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'all_data.dat'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#,'a+b')\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'dates.dat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Adam Shelboourne/Uni/Physics/Astr310/Python/mu/daily/all_data.dat'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Set the common time grid onto which each night is sampled. The common grid \n",
    "# is defined by the start time defined below, and the number of hours from that time\n",
    "beginh = 16 # Hour of start time (hour)\n",
    "beginm = 30 # Hour of start time (minute)\n",
    "nhrs = 15   # Number of hours to extend time grid\n",
    "\n",
    "# Output file name for storing the big 2D array of resampled SQM values. Remove the file\n",
    "# if it already exists.\n",
    "outfile = dir + 'all_data.dat'\n",
    "os.remove(outfile) if os.path.exists(outfile) else None\n",
    "\n",
    "# Open up files for the outputs. There is one for the SQM float values, and another for\n",
    "# storing the data of each night. These are merged later, but couldn't easily see how to\n",
    "# do this directly in one file, due to mixed data types.\n",
    "f=open(dir+'all_data.dat') #,'a+b')\n",
    "f2=open(dir+'dates.dat','w')\n",
    "\n",
    "# Parse the data directory and pick up all the relevant data file names. Note that the directory\n",
    "# listing will set the order of the files. The default pysqm.py output files are dated, so this should\n",
    "# be OK.\n",
    "for name in glob.glob(dir+'20*.dat'):\n",
    "# Read in the data set\n",
    "    dataset = pandas.read_csv(name,comment=\"#\",sep=';',names=names)\n",
    "#Establish Local Time as index\n",
    "    times = pandas.to_datetime(dataset['LocalDateTime'])\n",
    "    dataset.index=times\n",
    "# Set up the common time span, but adapted for the current data's date\n",
    "    rng = pandas.date_range(pandas.to_datetime(dataset['LocalDateTime']).dt.date[0] + pandas.DateOffset(hours=beginh,minutes=beginm), periods=nhrs*60, freq='T')\n",
    "# Set the new time grid as the index\n",
    "    d = {'Date' : pandas.Series(rng)}\n",
    "    df = pandas.DataFrame(d)\n",
    "    dates = pandas.to_datetime(df['Date'])\n",
    "    df.index = dates\n",
    "# Resample the original data to minutes, spanning the common grid\n",
    "    start = dates.min().strftime('%H:%M:%S')\n",
    "    end = dates.max().strftime('%H:%M:%S')\n",
    "    sub = dataset.between_time(start_time=start,end_time=end,include_start=True,include_end=True).resample('T').mean().interpolate(method='linear')\n",
    "# Combine data with this grid, thus putting it on the common frame\n",
    "    comb = df.join(sub['MSAS'])\n",
    "# Save data as new line in output file\n",
    "    numpy.savetxt(f,[numpy.array(comb['MSAS'])[0:(nhrs*60)-1]])\n",
    "    f2.write(str(pandas.to_datetime(dataset['LocalDateTime']).dt.date[0])+'\\n')\n",
    "\n",
    "# Close the files\n",
    "f.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
